{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for running the code in the notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport RNN_model, RNN_apply_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If not have run before\n",
    "'''\n",
    "import RNN_apply_ind, os, json, argparse\n",
    "\n",
    "folder_path = r'C:\\Users\\qilei.zhang\\OneDrive - Frontier Airlines\\Documents\\Data\\USconti'\n",
    "seats_file_name = r'\\Schedule_Monthly_Summary_Report_Conti.csv'\n",
    "perf_file_name = r'\\Airline_Performance_Report_Conti.csv'\n",
    "apply_file_name = '\\Schedule_Monthly_Summary_2023Q1234.csv'\n",
    "# Load parameters from the JSON file.\n",
    "if not os.path.exists('parameters.json'):\n",
    "    print(\"parameters.json does not exist, Find the file and put it in the same folder as this file\")\n",
    "with open('parameters.json', 'r') as f:\n",
    "    args = argparse.Namespace(**json.load(f))\n",
    "\n",
    "RNN_apply_ind.main_apply(args, folder_path, seats_file_name, perf_file_name, apply_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "quick look at the result\n",
    "'''\n",
    "import pandas as pd\n",
    "from RNN_apply_ind import DataAna\n",
    "\n",
    "apply_filename='./data/applying_data.csv'\n",
    "ana_df_name = \"./results/data_to_ana_apply.csv\"\n",
    "orig_df = pd.read_csv(apply_filename)\n",
    "\n",
    "ana = DataAna(ana_df_name)\n",
    "ana.merge_previous_data(orig_df)\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Enter airline and route, separated by comma, or 'c' to exit: \")\n",
    "    if user_input.lower() == 'c':\n",
    "        break\n",
    "    try:\n",
    "        airline, route = user_input.split(',')\n",
    "        airline = airline.strip()  # remove possible leading/trailing whitespaces\n",
    "        route = route.strip()  # remove possible leading/trailing whitespaces\n",
    "        ana.plot_prediction(airline, route)\n",
    "    except ValueError:\n",
    "        print(\"Invalid input, please enter the airline and route separated by a comma or 'continue' to proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new performance data and seats data to original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Add new performance data and seats data to original data\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = r'C:\\Users\\qilei.zhang\\OneDrive - Frontier Airlines\\Documents\\Data\\USconti'\n",
    "seats_file_name = r'\\Schedule_Monthly_Summary_Report_Conti.csv'\n",
    "perf_file_name = r'\\Airline_Performance_Report_Conti.csv'\n",
    "\n",
    "seats_file_new = r'\\Schedule_Monthly_Summary_2023Q1.csv'\n",
    "perf_file_new = r'\\Airline_Performance_Report_USconti_2023Q1.csv'\n",
    "\n",
    "seats_df = pd.read_csv(folder_path + seats_file_name)\n",
    "perf_df = pd.read_csv(folder_path + perf_file_name)\n",
    "\n",
    "seats_df_new = pd.read_csv(folder_path + seats_file_new)\n",
    "perf_df_new = pd.read_csv(folder_path + perf_file_new)\n",
    "\n",
    "\n",
    "# Check the column names are the same othewise not proceed\n",
    "if not (seats_df.columns == seats_df_new.columns).all():\n",
    "    print(\"Column names are not the same, please check the data\")\n",
    "    raise ValueError\n",
    "\n",
    "if not (perf_df.columns == perf_df_new.columns).all():\n",
    "    print(\"Column names are not the same, please check the data\")\n",
    "    raise ValueError\n",
    "\n",
    "# Check the data types are the same othewise not proceed\n",
    "if not (seats_df.dtypes == seats_df_new.dtypes).all():\n",
    "    print(\"Column types are not the same, please check the data\")\n",
    "    raise ValueError\n",
    "\n",
    "if not (perf_df.dtypes == perf_df_new.dtypes).all():\n",
    "    print(\"Column types are not the same, please check the data\")\n",
    "    raise ValueError\n",
    "\n",
    "seats_df = pd.concat([seats_df, seats_df_new])\n",
    "perf_df = pd.concat([perf_df, perf_df_new])\n",
    "\n",
    "seats_df.to_csv(folder_path + seats_file_name, index=False)\n",
    "perf_df.to_csv(folder_path + perf_file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if the dates are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Boundary quarter (<): Q2 2022\n",
      "Test data (>): Q4 2020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Q2 2022', 'Q1 2020', 'Q4 2020')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from RNN_model import calculate_quarters\n",
    "\n",
    "calculate_quarters(pred_num_quarters=3, seq_num=10, start_quarter=\"Q1 2023\", skip_quarters=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically tune the hyperparameters and record the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>drop_prob</th>\n",
       "      <th>bidirectional</th>\n",
       "      <th>if_skip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>20</td>\n",
       "      <td>0.35</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>20</td>\n",
       "      <td>0.35</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>20</td>\n",
       "      <td>0.35</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>20</td>\n",
       "      <td>0.35</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>30</td>\n",
       "      <td>0.35</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>30</td>\n",
       "      <td>0.35</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>30</td>\n",
       "      <td>0.35</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>30</td>\n",
       "      <td>0.35</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.35</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.35</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.35</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.35</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>0.35</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>0.35</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>0.35</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>0.35</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  epochs  drop_prob  bidirectional  if_skip\n",
       "0          0.0010      20       0.35           True     True\n",
       "1          0.0010      20       0.35           True    False\n",
       "2          0.0010      20       0.35          False     True\n",
       "3          0.0010      20       0.35          False    False\n",
       "4          0.0010      20       0.40           True     True\n",
       "5          0.0010      20       0.40           True    False\n",
       "6          0.0010      20       0.40          False     True\n",
       "7          0.0010      20       0.40          False    False\n",
       "8          0.0010      30       0.35           True     True\n",
       "9          0.0010      30       0.35           True    False\n",
       "10         0.0010      30       0.35          False     True\n",
       "11         0.0010      30       0.35          False    False\n",
       "12         0.0010      30       0.40           True     True\n",
       "13         0.0010      30       0.40           True    False\n",
       "14         0.0010      30       0.40          False     True\n",
       "15         0.0010      30       0.40          False    False\n",
       "16         0.0001      20       0.35           True     True\n",
       "17         0.0001      20       0.35           True    False\n",
       "18         0.0001      20       0.35          False     True\n",
       "19         0.0001      20       0.35          False    False\n",
       "20         0.0001      20       0.40           True     True\n",
       "21         0.0001      20       0.40           True    False\n",
       "22         0.0001      20       0.40          False     True\n",
       "23         0.0001      20       0.40          False    False\n",
       "24         0.0001      30       0.35           True     True\n",
       "25         0.0001      30       0.35           True    False\n",
       "26         0.0001      30       0.35          False     True\n",
       "27         0.0001      30       0.35          False    False\n",
       "28         0.0001      30       0.40           True     True\n",
       "29         0.0001      30       0.40           True    False\n",
       "30         0.0001      30       0.40          False     True\n",
       "31         0.0001      30       0.40          False    False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Create combinations of parameters to tune\n",
    "'''\n",
    "\n",
    "# Change the parameters.json file to have the following\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "params_to_tune = {\n",
    "    \"learning_rate\": [1e-03, 1e-04],\n",
    "    # \"momentum\": [0.95, 0.98],\n",
    "    # \"batch_size\": [64, 128],\n",
    "    \"epochs\": [20, 30],\n",
    "    # \"n_layers\": [4, 5],\n",
    "    \"drop_prob\": [0.35, 0.4],\n",
    "    \"bidirectional\": [True, False], \n",
    "    \"if_skip\": [True, False], \n",
    "    # \"if_feed_drop\": [True, False], \n",
    "    # \"if_feed_norm\": [True, False],\n",
    "}\n",
    "\n",
    "# Generate all combinations\n",
    "keys, values = zip(*params_to_tune.items())\n",
    "param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(param_combinations)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(resume_training=False, MSE_or_GaussianNLLLoss='GaussianNLLLoss', pred_num_quarters=3, seq_num=10, if_add_time_info=False, learning_rate=0.0001, momentum=0.95, batch_size=64, epochs=20, num_workers=1, shuffle=True, fixed_seed=True, rnn_type='LSTM', n_layers=4, drop_prob=0.35, num_heads=6, start_year=2004, checkpoint_file_name='checkpoint_20.pth', bidirectional=True, if_skip=False, if_feed_drop=True, if_feed_norm=True, start_quarter='Q1 2023', skip_quarters=2, validation_type='Val', tune=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load parameters from the JSON file. Check if the parameters are loaded correctly.\n",
    "with open('parameters.json', 'r') as f:\n",
    "    args = argparse.Namespace(**json.load(f))\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "learning_rate 0.001\n",
      "epochs 20\n",
      "drop_prob 0.35\n",
      "bidirectional True\n",
      "if_skip True\n",
      "1\n",
      "learning_rate 0.001\n",
      "epochs 20\n",
      "drop_prob 0.35\n",
      "bidirectional True\n",
      "if_skip False\n",
      "2\n",
      "learning_rate 0.001\n",
      "epochs 20\n",
      "drop_prob 0.35\n",
      "bidirectional False\n",
      "if_skip True\n",
      "3\n",
      "learning_rate 0.001\n",
      "epochs 20\n",
      "drop_prob 0.35\n",
      "bidirectional False\n",
      "if_skip False\n",
      "4\n",
      "learning_rate 0.001\n",
      "epochs 20\n",
      "drop_prob 0.4\n",
      "bidirectional True\n",
      "if_skip True\n",
      "5\n",
      "learning_rate 0.001\n",
      "epochs 20\n",
      "drop_prob 0.4\n",
      "bidirectional True\n",
      "if_skip False\n",
      "6\n",
      "learning_rate 0.001\n",
      "epochs 20\n",
      "drop_prob 0.4\n",
      "bidirectional False\n",
      "if_skip True\n",
      "7\n",
      "learning_rate 0.001\n",
      "epochs 20\n",
      "drop_prob 0.4\n",
      "bidirectional False\n",
      "if_skip False\n",
      "8\n",
      "learning_rate 0.001\n",
      "epochs 30\n",
      "drop_prob 0.35\n",
      "bidirectional True\n",
      "if_skip True\n",
      "9\n",
      "learning_rate 0.001\n",
      "epochs 30\n",
      "drop_prob 0.35\n",
      "bidirectional True\n",
      "if_skip False\n",
      "10\n",
      "learning_rate 0.001\n",
      "epochs 30\n",
      "drop_prob 0.35\n",
      "bidirectional False\n",
      "if_skip True\n",
      "11\n",
      "learning_rate 0.001\n",
      "epochs 30\n",
      "drop_prob 0.35\n",
      "bidirectional False\n",
      "if_skip False\n",
      "12\n",
      "learning_rate 0.001\n",
      "epochs 30\n",
      "drop_prob 0.4\n",
      "bidirectional True\n",
      "if_skip True\n",
      "13\n",
      "learning_rate 0.001\n",
      "epochs 30\n",
      "drop_prob 0.4\n",
      "bidirectional True\n",
      "if_skip False\n",
      "14\n",
      "learning_rate 0.001\n",
      "epochs 30\n",
      "drop_prob 0.4\n",
      "bidirectional False\n",
      "if_skip True\n",
      "15\n",
      "learning_rate 0.001\n",
      "epochs 30\n",
      "drop_prob 0.4\n",
      "bidirectional False\n",
      "if_skip False\n",
      "16\n",
      "learning_rate 0.0001\n",
      "epochs 20\n",
      "drop_prob 0.35\n",
      "bidirectional True\n",
      "if_skip True\n",
      "17\n",
      "learning_rate 0.0001\n",
      "epochs 20\n",
      "drop_prob 0.35\n",
      "bidirectional True\n",
      "if_skip False\n",
      "18\n",
      "learning_rate 0.0001\n",
      "epochs 20\n",
      "drop_prob 0.35\n",
      "bidirectional False\n",
      "if_skip True\n",
      "19\n",
      "learning_rate 0.0001\n",
      "epochs 20\n",
      "drop_prob 0.35\n",
      "bidirectional False\n",
      "if_skip False\n",
      "20\n",
      "learning_rate 0.0001\n",
      "epochs 20\n",
      "drop_prob 0.4\n",
      "bidirectional True\n",
      "if_skip True\n",
      "21\n",
      "learning_rate 0.0001\n",
      "epochs 20\n",
      "drop_prob 0.4\n",
      "bidirectional True\n",
      "if_skip False\n",
      "22\n",
      "learning_rate 0.0001\n",
      "epochs 20\n",
      "drop_prob 0.4\n",
      "bidirectional False\n",
      "if_skip True\n",
      "23\n",
      "learning_rate 0.0001\n",
      "epochs 20\n",
      "drop_prob 0.4\n",
      "bidirectional False\n",
      "if_skip False\n",
      "24\n",
      "learning_rate 0.0001\n",
      "epochs 30\n",
      "drop_prob 0.35\n",
      "bidirectional True\n",
      "if_skip True\n",
      "25\n",
      "learning_rate 0.0001\n",
      "epochs 30\n",
      "drop_prob 0.35\n",
      "bidirectional True\n",
      "if_skip False\n",
      "26\n",
      "learning_rate 0.0001\n",
      "epochs 30\n",
      "drop_prob 0.35\n",
      "bidirectional False\n",
      "if_skip True\n",
      "27\n",
      "learning_rate 0.0001\n",
      "epochs 30\n",
      "drop_prob 0.35\n",
      "bidirectional False\n",
      "if_skip False\n",
      "28\n",
      "learning_rate 0.0001\n",
      "epochs 30\n",
      "drop_prob 0.4\n",
      "bidirectional True\n",
      "if_skip True\n",
      "29\n",
      "learning_rate 0.0001\n",
      "epochs 30\n",
      "drop_prob 0.4\n",
      "bidirectional True\n",
      "if_skip False\n",
      "30\n",
      "learning_rate 0.0001\n",
      "epochs 30\n",
      "drop_prob 0.4\n",
      "bidirectional False\n",
      "if_skip True\n",
      "31\n",
      "learning_rate 0.0001\n",
      "epochs 30\n",
      "drop_prob 0.4\n",
      "bidirectional False\n",
      "if_skip False\n"
     ]
    }
   ],
   "source": [
    "import RNN_model\n",
    "import RNN_apply_ind, os\n",
    "\n",
    "folder_path = r'C:\\Users\\qilei.zhang\\OneDrive - Frontier Airlines\\Documents\\Data\\USconti'\n",
    "seats_file_name = r'\\Schedule_Monthly_Summary_Report_Conti.csv'\n",
    "perf_file_name = r'\\Airline_Performance_Report_Conti.csv'\n",
    "apply_file_name = 'Schedule_Monthly_Summary_2023Q1234.csv'\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    print(idx)\n",
    "    # Extract parameters from the row\n",
    "    params = row.to_dict()\n",
    "\n",
    "    # Load parameters from the JSON file.\n",
    "    with open('parameters.json', 'r') as f:\n",
    "        args = argparse.Namespace(**json.load(f))\n",
    "\n",
    "    # assign the all parameters from the row to the args object\n",
    "    for key, value in params.items():\n",
    "        setattr(args, key, value)\n",
    "        print(key, value)\n",
    "\n",
    "    # Check types of certain parameters, and transform them if necessary\n",
    "    if not isinstance(args.epochs, int):\n",
    "        args.epochs = int(args.epochs)\n",
    "    if not isinstance(args.batch_size, int):\n",
    "        args.batch_size = int(args.batch_size)\n",
    "    if not isinstance(args.n_layers, int):\n",
    "        args.n_layers = int(args.n_layers)\n",
    "\n",
    "    # Run the model\n",
    "    # Run Training\n",
    "    RNN_model.main_program(args, folder_path, seats_file_name, perf_file_name, tune_folder=str(idx))\n",
    "\n",
    "    # Run validation\n",
    "    RNN_apply_ind.main_apply(args, folder_path, seats_file_name, perf_file_name, apply_file_name, tune_folder=str(idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run current forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run current forecast\n",
    "# Need to put validation_type to be \"test\" otherwise use \"Val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RNN_apply_ind, os, json, argparse\n",
    "\n",
    "folder_path = r'C:\\Users\\qilei.zhang\\OneDrive - Frontier Airlines\\Documents\\Data\\USconti'\n",
    "seats_file_name = r'\\Schedule_Monthly_Summary_Report_Conti.csv'\n",
    "perf_file_name = r'\\Airline_Performance_Report_Conti.csv'\n",
    "apply_file_name = '\\Schedule_Monthly_Summary_2023Q1234.csv'\n",
    "# Load parameters from the JSON file.\n",
    "if not os.path.exists('parameters.json'):\n",
    "    print(\"parameters.json does not exist, Find the file and put it in the same folder as this file\")\n",
    "with open('parameters.json', 'r') as f:\n",
    "    args = argparse.Namespace(**json.load(f))\n",
    "\n",
    "key = \"validation_type\"\n",
    "value = \"test\"\n",
    "setattr(args, key, value)\n",
    "\n",
    "RNN_apply_ind.main_apply(args, folder_path, seats_file_name, perf_file_name, apply_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
